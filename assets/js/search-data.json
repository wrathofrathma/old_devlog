{
  
    
        "post0": {
            "title": "Creating a REST API with Express.js (2/X): Sqlite Database",
            "content": "Overview . In this post we’ll be implementing a basic SQLite database to contain our user data and tweets, adding async support to our database, and using basic migration scripts to setup our database. . Why async? . By default the sqlite3 database doesn’t have async support build in. This is probably fine, but I was running into issues where express wouldn’t wait for my query to return to continue processing the request. Specifically in cases where I was implementing error handling, the request would complete before the error was generated. I’m hoping to abuse the await keyword to so that I can wait for my query to resolve before continuing. It also allows us to use a callback style structure, which is nice. . Code . All code from this series can be found here . https://github.com/wrathofrathma/rest-express . All code from this post can be found here . https://github.com/wrathofrathma/rest-express/tree/Async-SQLite-%26-Migrations . Setup . The first thing we need to do is install the node drivers for the database we’re using, sqlite3. Additionally we need to install the wrapper package sqlite which provides async support. To install both use the command below. . npm install sqlite3 sqlite . If we try to use the database now we’ll run into issues with the babel transpiler since it doesn’t come with async/await support out of the box. So we need to install a few more packages. . npm install @babel/runtime @babel/plugin-transform-runtime . Now we need to edit our package.json to configure and enable the plugin. . //package.json ... &quot;babel&quot;: { &quot;presets&quot;: [ &quot;@babel/preset-env&quot; ], &quot;plugins&quot;:[ [&quot;@babel/plugin-transform-runtime&quot;, { &quot;regenerator&quot;: true }] ] }, . Creating an importable database module . When using node modules, if you use an import statement on a directory, it’ll search for an index.js file in that directory and import that. So for our database, we would like to be able to just do an import something from &#39;./database&#39;. . Basic Database Module . Let’s create our index.js file in a new directory called server/database/ so that we can import it as a module. The example code provided by the sqlite reference on npm for exporting the database via a module is below. You can look on the reference for the configuration options you can pass to the open() method. . import sqlite3 from &#39;sqlite3&#39;; import { open } from &#39;sqlite&#39;; export async function openDb() { return open({ filename: &quot;./sqlite.db&quot;, driver: sqlite3.Database }); } . Enabling foreign keys . This works if we don’t want to work with foreign keys in our SQL database, but if you do, you’ll run into the same issue I did. Sqlite kept erroring out with a message about a foreign key mismatch, but what was really happening is SQLite doesn’t have foreign key support out of the box. You need to specify during each database session. . The command we need to run to enable it during every runtime is this… . sqlite&gt; PRAGMA foreign_keys = ON; . So let’s add it to our export function so we always use it. . import sqlite3 from &#39;sqlite3&#39;; import { open } from &#39;sqlite&#39;; export async function openDb() { const db = await open({ filename: &quot;./sqlite.db&quot;, driver: sqlite3.Database }); await db.exec(&quot;PRAGMA foreign_keys = ON;&quot;); return db; } . Using our database module . Now our database is importable as a module! All we need to do to use our database in a file is . import { openDb } from &#39;./dist/database&#39;; async function somefunction() { const db = await openDb(); //do stuff } . You can alternatively use Promise syntax . import { openDb } from &#39;./dist/database&#39;; async function somefunction() { await openDb().then(async (db) =&gt; { //do stuff }) } . Migrations . I was sorely missing the migration scripts provided in Adonis.js and was going to look into a migration framework, but the sqlite package that provides our async support also provides basic sql migrations! . Setup . migrations.js . The first thing we need to do is create a migrations.js file in our server/database/ folder to house our code. . Once we do that, we need to add code to open our database, similar to how we did in our module, and then call db.migrate(). . import { open } from &#39;sqlite&#39;; import sqlite3 from &#39;sqlite3&#39;; const db_path = &quot;./sqlite.db&quot; open({ filename: db_path, driver: sqlite3.Database }) .then(async (db) =&gt; { await db.migrate() }); . The default parameters of db.migrate() will look for migration scripts in a ./migrations directory. Or you can pass a configuration object with a migrationsPath string. . Since we know where it will look for migration scripts by default, let’s just create a directory in our project root called migrations/. . mkdir migrations . Realistically this can be anywhere, as long as we pass the migrationsPath string. Just make sure to not have the string look in the dist/ folder since that gets overwritten by babel &amp; isn’t included/copied in the transpile from the server/ folder by default. . Migration files . The migration files themselves need to follow the naming convention XXX-somename.sql, where XXX is incrementing numbers starting at 001. If you don’t follow this convention, the migration script won’t register our files. Other than that, you can use the example migrations provided by the sqlite package as reference for how to create your sql based migration files. . Since I’m making a twitter clone, I need to have a table for users and one for tweets. So I’ll make a migration script for both . 001-users.sql | 002-tweets.sql | . Notice in the following code snippets, that Up &amp; Down have their own comment blocks. I believe this is how the migration script differentiates the up(build) and down(delete) scripts. Besides that it’s basic SQL. . I created a basic user table off of my minimalistic requirements . a unique user id | requiring a unique username | a required password | . migrations/users.sql . -- -- Up -- CREATE TABLE users ( id INTEGER PRIMARY KEY, username TEXT NOT NULL UNIQUE, password TEXT NOT NULL ); -- -- Down -- DROP TABLE users; . This snippet will create our users table to our spec, and then when we need to rebuild or tear down using our migration script, the line DROP TABLE users; will be run. . One cool thing about sqlite is that when we use this table, we don’t have to pass in an id field. By default an INTEGER PRIMARY KEY will be equal to the rowid. Definitely need to do some testing to see if anything weird can arise from that later. . The tweets table also has fairly minimalist requirements right now . a unique tweet id | the tweet contents | storing the user who tweeted | . migrations/tweets.sql . -- -- Up -- CREATE TABLE tweets ( id INTEGER PRIMARY KEY, contents TEXT NOT NULL, hashtags TEXT, user_id INTEGER NOT NULL, CONSTRAINT fk_userid FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE ); -- -- Down -- DROP TABLE tweets; . The only notable thing about this table is this line . CONSTRAINT fk_userid FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE . This creates a constraint on the tweet to delete this database entry if the forerign key we’re referencing is deleted. . Running migrations . Now that we have very basic migration scripts, we need to setup our project to run them. . Since we’ve already setup our migrations.js file, we just need to configure how to run them. Typically migrations aren’t run at runtime, so we’ll be creating a separate script in our package.json to run them for us. . I separated the command into two parts since our migration script is in the server/ directory that babel transpiles. We’ll want to transpile before executing. . //package.json ... &quot;scripts&quot;: { ... &quot;dbinit&quot;: &quot;node ./dist/database/migrations.js&quot;, &quot;migrations&quot;: &quot;npm-run-all clean transpile dbinit&quot; } . Now you should be able to just run the following command to create your database =) . npm run migrations . Closing . Honestly, the migrations seem a bit weaker than adonis.js, so maybe in the future I’ll look into a proper migration framework. But for now we have migration scripts and an importable method to open our database with async support. In the next post we’ll make sure it all works with unit tests! . References . https://www.sqlitetutorial.net/ | https://www.npmjs.com/package/sqlite | https://babeljs.io/docs/en/babel-plugin-transform-runtime#docsNav | https://github.com/kriasoft/node-sqlite/tree/master/migrations | .",
            "url": "https://www.kyso.dev/express/webdev/sqlite/migrations/2021/03/23/Sqlite-Database.html",
            "relUrl": "/express/webdev/sqlite/migrations/2021/03/23/Sqlite-Database.html",
            "date": " • Mar 23, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Creating a REST API with Express.js (1/X): Express Scaffolding",
            "content": "Overview . In the project 2 description post I set a goal to learn Express.js by implementing some of the basic functionality I enjoyed from Adonis.js. . Over this series of posts I’ll be learning to implement many of these functionalities by making a basic REST API with Express.js. . What’s covered in this post . This first post is mostly just a summarized version of this tutorial on setting up an express project with ES6 module support and a hot reload dev environment. I highly suggest reading the original article, I’m just going to reiterate the same stuff for self-reference later and get into other stuff in the next post. . Code . All code from this series can be found here . https://github.com/wrathofrathma/rest-express . All code from this post can be found here . https://github.com/wrathofrathma/rest-express/tree/ES6-Express-Generator-Boilerplate . Intro . Scaffolding with babel &amp; ES6 module support with express-generator . The goal of this post is to setup a development environment… . where we contain our coding to a source directory | with ES6 module support | that uses babel to transpile the ES6 code in our source directory to ES5 in a dist directory | where the development runtime reloads everytime we save changes to our code (hot reloading) | with scripts in our package.json do all of our dirty work. | . Why do we need ES6+ Support? . Honestly, we probably don’t entirely but it’s really convenient. Enabling import from syntax for more controlled imports and modules being built into ES6 are reason enough to use it. Also almost every tutorial online seems to be using it, I tried avoiding it for awhile but this makes life a bit simpler. . Project Setup . express-generator . First thing we need to is use express-generator to create the starting scaffold of our project. We pass our project-name(mine being rest-express) to the generator as well as --no-view since we don’t need any sort of frontend templating. . npx express-generator rest-express --no-view . Now cd into the directory and install all of our dependencies . cd rest-express npm install . Next, or while they install, we need to restructure our scaffolded project. . Create a server/ folder | Put bin/, app.js, and routes/ in the server/ folder | Rename www in the bin/ folder to www.js | . Lastly, we need to modify our start script to point to the binary in the dist/bin/ folder rather than bin/. Keep in mind we’ll be using babel to transpile our server/ directory to our dist/ directory. . // package.json { &quot;name&quot;: &quot;your-project-name&quot;, // ....other details &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot; } } . Converting source to ES6 . So now we have to go to each of our source files and convert them to ES6. This is mostly just replacing require() with import from syntax and some exports. . The article was kind enough to give copy &amp; pastable code, or you can go through and do it yourself. Just focus on imports(tops) and exports (bottom). . Code for bin/www.js . // bin/www.js /** * Module dependencies. */ import app from &#39;../app&#39;; import debugLib from &#39;debug&#39;; import http from &#39;http&#39;; const debug = debugLib(&#39;your-project-name:server&#39;); // ..generated code below. . Code for routes/index.js and routes/users.js . // routes/index.js and users.js import express from &#39;express&#39;; var router = express.Router(); // ..stuff below export default router; . Code for app.js . // app.js import express from &#39;express&#39;; import path from &#39;path&#39;; import cookieParser from &#39;cookie-parser&#39;; import logger from &#39;morgan&#39;; import indexRouter from &#39;./routes/index&#39;; import usersRouter from &#39;./routes/users&#39;; var app = express(); app.use(logger(&#39;dev&#39;)); app.use(express.json()); app.use(express.urlencoded({ extended: false })); app.use(cookieParser()); app.use(express.static(path.join(__dirname, &#39;../public&#39;))); app.use(&#39;/&#39;, indexRouter); app.use(&#39;/users&#39;, usersRouter); export default app; . Be sure to change the path to public/ which is still at the root directory, to ../public. . After that we’re finished with the conversion to ES6 syntax and move onto scripts. . Script Setup . In the package.json file at the root of your project you can define scripts. These scripts can be called by npm run script-name and are used and composed together to perform a multitude of tasks in your project. . Install npm-run-all . In order to compose multiple tasks, we need to install the package npm-run-all. . npm install npm-run-all . Install babel, nodemon, and rimraf . Babel is our ES6 -&gt; ES5 javascript transpiler. | nodemon watches a directory for changes and performs specified tasks when changes are detected. | rimraf is a package that makes deleting files &amp; directories simple npm install @babel/core @babel/cli @babel/preset-env nodemon rimraf . | . Adding transpile script . Now we can setup our package.json to transpile our code whenever we run npm run transpile in our project directory. . First thing we need to do is configure babel to know what syntax we want to transpile to, and thankfully the preset-env is what we want. So we get away with just adding this babel object to our package.json. . // package.json { // .. contents above &quot;babel&quot;: { &quot;presets&quot;: [&quot;@babel/preset-env&quot;] }, } . Next we need to add the transpile script to the scripts section of our package.json. . // package.json &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot;, &quot;transpile&quot;: &quot;babel ./server --out-dir dist&quot;, } . We can now test this by running this command in your project directory. . npm run transpile . This should take all of the code in the source directory server/ and transpile it to ES5 code in the dist/ directory. Now would be a good time to try running our server. To give it a run we can run this command. . npm run server . Clean Script . Now that we have our transpile script creating a new directory, we need a clean script to delete our dist/ directory so we have a clean directory to work with. This is where rimraf comes in. . Add this to your package.json . &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot;, &quot;transpile&quot;: &quot;babel ./server --out-dir dist&quot;, &quot;clean&quot;: &quot;rimraf dist&quot; } . This new ‘clean’ command will remove the folder dist/ from our project root whenever we call npm run clean. . Now we can use npm-run-all to combine these two scripts, clean and transpile, into a build script that does both for us automatically. . &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot;, &quot;transpile&quot;: &quot;babel ./server --out-dir dist&quot;, &quot;clean&quot;: &quot;rimraf dist&quot;, &quot;build&quot;: &quot;npm-run-all clean transpile&quot; } . Develoment enviroment script . For our development environment script, we want to remove our old distribution directory, transpile our code, set the node environment to development and then run the server. . &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot;, &quot;transpile&quot;: &quot;babel ./server --out-dir dist&quot;, &quot;clean&quot;: &quot;rimraf dist&quot;, &quot;build&quot;: &quot;npm-run-all clean transpile&quot;, &quot;dev&quot;: &quot;NODE_ENV=development npm-run-all build server&quot;, } . Production environment script . Similar to the dev script, we also want a production script that peforms the same tasks, but sets the node environment to production. . Additionally, we want to add a start script since most deployment platforms like AWS, Firebase, Heroku call the start script to start the server. . &quot;scripts&quot;: { &quot;server&quot;: &quot;node ./dist/bin/www&quot;, &quot;transpile&quot;: &quot;babel ./server --out-dir dist&quot;, &quot;clean&quot;: &quot;rimraf dist&quot;, &quot;build&quot;: &quot;npm-run-all clean transpile&quot;, &quot;dev&quot;: &quot;NODE_ENV=development npm-run-all build server&quot;, &quot;prod&quot;: &quot;NODE_ENV=production npm-run-all build server&quot;, &quot;start&quot;: &quot;npm run prod&quot;, } . Hot reloading . The last thing to setup from this section is hot reloading on the development environment. Remember this uses the nodemon package, so we need to configure it a bit in our package.json. . // package.json ... &quot;nodemonConfig&quot;: { &quot;exec&quot;: &quot;npm run dev&quot;, &quot;watch&quot;: [&quot;server/*&quot;, &quot;public/*&quot;], &quot;ignore&quot;: [&quot;**/__tests__/**&quot;, &quot;*.test.js&quot;, &quot;*.spec.js&quot;] }, &quot;scripts&quot;: { // ... other scripts &quot;watch:dev&quot;: &quot;nodemon&quot; } . In the nodemon config, you can see we specify what command to run when a file changes under &quot;exec&quot;: &quot;npm run dev&quot;, what directories and files to watch for changes, and what patterns to ignore. . Now we can start a hot reloading development environment with . npm run watch:dev . Closing . It felt a little weird mostly summarizing for one post, but I wanted to avoid another monolithic post if I could and wanted to document the entire process. . Anyways, now you know how to setup a fairly decent dev environment! . Thanks for reading. . References . https://expressjs.com/ | https://www.freecodecamp.org/news/how-to-enable-es6-and-beyond-syntax-with-node-and-express-68d3e11fe1ab/ | .",
            "url": "https://www.kyso.dev/express/webdev/es6/2021/03/22/Express-Scaffolding.html",
            "relUrl": "/express/webdev/es6/2021/03/22/Express-Scaffolding.html",
            "date": " • Mar 22, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Hosting an Express.js server on Firebase functions",
            "content": "Overview . For my next few projects I knew I was planning on learning express.js, but hosting was a concern in my mind. I definitely wanted a place to host my progress for cheap. I was thinking of renting a VPS from ovh, which I might still do, but I found out a few days ago that it’s possible to host express.js servers on firebase using their “functions”. . It’s also free for the first 2,000,000 function invocations, or in our case the first 2,000,000 API calls. So it’s basically perfect for our little hobby projects. We also can set monthly budgets, so a random influx of traffic won’t fuck us either. . So why is it even compatible in the first place? . In short, the parameters passed to firebase functions’ onRequest() method were designed after Express.js’ Request &amp; Response objects. . One of the firebase engineers explained why on StackOverflow. . This all works because under the covers, an Express app is actually just a function that takes a Node.js HTTP request and response and acts on them with some automatic sugaring such as routing. So you can pass an Express router or app to a Cloud Function handler without issue, because Express’s req and res objects are compatible with the standard Node.js versions. Basically, it’s a “double Express” app where one app is calling another. . As far as function lifecycle and shared state goes: functions are spun up in ephemeral compute instances that may survive to process multiple requests, but may not. You cannot tune or guarantee whether or not a function will be invoked in the same compute instance from one invocation to the next. . You can create resources (such as an Express app) outside of the function invocation and it will be executed when the compute resources are spun up for that function. This will survive as long as the instance does; however, CPU/network are throttled down to effectively zero between invocations, so you can’t do any “work” outside of a function invocation’s lifecycle. Once the promise resolves (or you’ve responded to the HTTP request), your compute resources will be clamped down via throttling and may be terminated at any moment. . So it all works, pog. Let’s get started. . Setup . Create a firebase project . In the Firebase console click on “Add Project” and follow the dialogues until the project is created. Or use an existing project. . Then from the project page you’ll need to upgrade your project plan from the free “Spark” plan to the pay as you go “Blaze” plan. Most everything can still be free, and just make sure to set the budget to something you’re comfortable with(such as $0). . Install firebase tools . You can either globally install firebase-tools or run them from npx . npm install -g firebase-tools . Create a project . I’m not sure about adding firebase to an existing project, but the firebase binary can create a blank project. . You’ll need to login at least once. This will open the browser and prompt you for logging in. . firebase login . Next you create the project in the directory you want. This command will ask you to select a project from your firebase to link to this folder and then create a skeleton project with firebase features that you select(firestore, functions, etc…). . firebase init . Install express.js . Now that we have a blank project in the directory functions/, we cd into it and install our express server. . cd functions npm install express . Create the express app . Lastly we just edit the index.js . The base skeleton index.js is just . const functions = require(&quot;firebase-functions&quot;); . We initialize our express app like normal . const functions = require(&quot;firebase-functions&quot;); const express = require(&quot;express&quot;); const app = express(); app.get(&#39;/&#39;, (req, res) =&gt; { res.send(&quot;Hello world!&quot;) }) . Now we use the functions api to tell firebase to send requests to our express app and export it. . const functions = require(&quot;firebase-functions&quot;); const express = require(&quot;express&quot;); const app = express(); app.get(&#39;/&#39;, (req, res) =&gt; { res.send(&#39;Hello world&#39;) }) const server = functions.https.onRequest(app); module.exports = { server } . Deploying to firebase . Lastly we need to upload it to our firebase project. . Deploying is just one command . firebase deploy --only functions . After this, back in your firebase console for your project, under build -&gt; functions on the left, you should be able to see your deployed server with a link that looks like . https://REGION-APP_ID.cloudfunctions.net/server . Closing . Well, that’s it. The server should be queryable at that address. . Now I’m going to have to learn how to actually use express lol. . Resources . From now on I’m going to start adding all the resources I read/use. . https://codeburst.io/express-js-on-cloud-functions-for-firebase-f76b5506179 | https://firebase.google.com/docs/functions/get-started | https://expressjs.com/en/starter/hello-world.html | .",
            "url": "https://www.kyso.dev/express/firebase/webdev/2021/03/16/FirebaseExpress.html",
            "relUrl": "/express/firebase/webdev/2021/03/16/FirebaseExpress.html",
            "date": " • Mar 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Project 2 - Twitter Clone",
            "content": "Overview . So much like the first project, I’m going into this one with a list of things I’d like to learn. I don’t want to expand the scope of the frontend too much just yet since we’re completely switching backends. So let’s define some goals. . Project Goals . Reinforce the basics of Vue.js | Learn Express.js by recreating the functionality we took for granted in Adonis.js Authentication | Routing (with prefixes, params, etc) | Middleware | Exception handling | Database integration | Controllers? If that’s a thing | Cross-Origin Resource Sharing (CORS) maybe | Body parsing | . | Learn a database migration package | Learn firebase by using it for Auth | Hosting | Firestore or Realtime database | Functions - Found out this is compatible with express servers….so let’s just host that here. | . | . Based on these goals, I felt that building a twitter clone would be appropriate. The frontend design is relatively simple, so we’ll definitely reinforce our Vue.js knowledge. The backend should be a simple CRUD style REST API if we don’t do live messaging &amp; push notifications, but since we’re learning how to do this all in express from scratch it’ll be challenging in the right areas. . Closing . Unlike the last monolithic post, this project will be broken down into smaller updates as the project progresses. I’m thinking of aiming for 1 project every 1-2 weeks. We’ll see how well we can actually keep to that. . Thanks for reading. .",
            "url": "https://www.kyso.dev/webdev/twitter/project%202/2021/03/15/twitter.html",
            "relUrl": "/webdev/twitter/project%202/2021/03/15/twitter.html",
            "date": " • Mar 15, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Building a CRUD TODO with Vue 3.0 & Adonis.js",
            "content": "Overview . So this is my first real attempt at learning web development. I played around with it about a year ago and have certainly used a handful of microframeworks with python for a variety of projects, but I’ve never really committed to learning frontend or even proper backend. This time we’re committed. . All code for this project can be found here . https://github.com/wrathofrathma/vue-adonis-todo . My decision making on the stack I choose for my first project. . Backend Runtime: Node.js . I went with a javascript based engine for a few reasons. . I already need to work with javascript for the frontend | There are tons of jobs in the express.js market | I predict there will be first class support for things like websockets and webrtc | Learning php + javascript seemed like a bit much for a first project. So keeping it simple and consistent. | . Backend Framework: Adonis.js . Honestly, this was a hard decision to make. There are a lot of good node based frameworks, so why adonis? It came down to two points . Laravel is the king of php frameworks from what I hear, and adonis is attempting to be the javascript version of laravel. So why not give it a try. | I rather use a batteries included framework to start so I don’t get discouraged easier. | . Frontend Framework: Vue 3 . This was probably the simplest decision for me. From what I’ve read, out of Angular, React, and Vue, Vue is the most comfortable to program in. Even looking at React versus Vue code, Vue just seemed more approachable. Also the market for React developers is probably very saturated and competitive. . I choose the Vue 3 preview over Vue 2 just because I rather get ahead of the game. . Frontend Component Library: Primevue . This was a rather limited, but still tough decision. Since most component libraries aren’t updated for Vue 3 yet, I was pretty much limited to Element, Ionic, Primevue, or making my own in Tailwind. . Making my own components in Tailwind seems very attractive…but I think a large part of the battle as a developer is just knowing what is possible and where to look. Right now I don’t have any experience, so anything I design from scratch will be limited I think. . I went with Primevue because it has a lot of components, the free theme selection is pretty top notch, and they have versions for react &amp; angular(should I switch in the future). . A project to get started . From what I understand, CRUD TODO lists are basically the “hello world” of web development, so I sought out a tutorial matching these technologies and found a real gem of a tutorial by freecodecamp. . youtube: https://www.youtube.com/watch?v=dfEZlcPvez8 . Differences . There are a few key differences between the stack we’re using and the one in the tutorial video from 3 years ago. . Adonis.js’ structure has changed a little since the video release | Vue.js has been updated to Vue 3, which forces further changes | We’re using Primevue instead of Vuetify because Vuetify isn’t updated for Vue 3. | We’ve also added the material icon set because primeicons is quite limited. | . Building the backend . I’m a little torn between whether I should actually document the whole process or just note the challenges/differences I encountered. For posterity sake, I’m just going to go over everything but instead of show the full process, skip the repetitive parts and show mostly finished code. . Setup . The first hour or so of the tutorial is setting up the REST API using Adonis. . Installation . Installation of Adonis is quite straightforward. I installed it their CLI tool globally, but you can also invoke it with npx. . sudo npm i -g @adonisjs/cli . Scaffolding a new project . Using the Adonis CLI you can scaffold out a basic project easily with . adonis new server --api-only . The –api-only prevents it from using the fullstack blueprint and only includes the necessary files for building an API. . Running the Adonis development server . Running the adonis dev server is about as simple as it could be. . adonis serve --dev . While the dev server is running, it will watch for all changes in the directory and live update the runtime. . Right now, before any changes are made, if we visit the address the server is running on(defaulted to localhost:3333) we will get the response . { greeting: &quot;Hello world in JSON&quot; } . Routing . To add any meaningful behavior to our server we need to add routes. . All of the routes in Adonis.js are defined in start/routes.js. Below you can find the default configuration which includes the response we saw above. . &#39;use strict&#39; /* |-- | Routes |-- | | Http routes are entry points to your web application. You can create | routes for different URLs and bind Controller actions to them. | | A complete guide on routing is available here. | http://adonisjs.com/docs/4.1/routing | */ /** @type {typeof import(&#39;@adonisjs/framework/src/Route/Manager&#39;)} */ const Route = use(&#39;Route&#39;) Route.get(&#39;/&#39;, () =&gt; { return { greeting: &#39;Hello world in JSON&#39; } }) . While in the default file they define a callback function in the route definition, typically the route logic is defined in a “controller”. Controllers are just objects that have functions for the various routes related to the theme of the controller. . We can use the Adonis CLI to create a controller for users to register/login with. . adonis make:controller User . It’ll ask whether you want to create an HTTP or websocket controller, and for all cases of our REST API we’ll pick HTTP since we don’t need the realtime connection provided by websockets. . The controller skeleton is created at app/Controllers/HTTP/UserController.js . &#39;use strict&#39; class UserController { } module.exports = UserController . We defined a few methods inside of the UserController object to handle authentication. . &#39;use strict&#39; // use() is an adonis specific method that they recommend replacing require() with // Here we&#39;re importing the user lucid model const User = use(&quot;App/Models/User&quot;) class UserController { //Adding auth to the object passed gives us access to the Auth from the AuthProvider defined in app.js // Auth type is defined in config/auth.js async login({request, auth}) { // request.all groups together all the request parameters, then we use object deconstruction to get the necessary items const {email, password} = request.all(); //Auth attempt const token = await auth.attempt(email, password); return token; } async register({request}) { // request.all groups together all the request parameters, then we use object deconstruction to get the necessary items const { email, password } = request.all(); //Calls the asynchronous model method to create a new user. // Adonis comes with a UserSchema that already includes username, email, and password const user = await User.create({ email, password, username: email, }) return this.login(...arguments); } } module.exports = UserController . We can access these by creating routes in start/routes.js. . In this completed example, you’ll notice a few things going on . We’ve grouped the routes together and applied an ‘api’ route prefix. So now you access the registration route by posting a request to localhost:3333/api/auth/register | We’ve added authentication middleware to routes that require a user to be logged in to access | Some routes have parameters/variables in the route, such as tasks/:id. This :id variable is passed to the controller as a parameter. | . &#39;use strict&#39; /* |-- | Routes |-- | | Http routes are entry points to your web application. You can create | routes for different URLs and bind Controller actions to them. | | A complete guide on routing is available here. | http://adonisjs.com/docs/4.1/routing | */ /** @type {typeof import(&#39;@adonisjs/framework/src/Route/Manager&#39;)} */ const Route = use(&#39;Route&#39;) // Route.get(&#39;/&#39;, () =&gt; { // return { greeting: &#39;Hello world in JSON&#39; } // }) // Groups routes together by a prefix Route.group(() =&gt; { //Sends the requests to our controller method created using adonis make:controller User // then defining the register method Route.post(&#39;auth/register&#39;, &quot;UserController.register&quot;) Route.post(&#39;auth/login&#39;, &quot;UserController.login&quot;) Route.get(&#39;projects&#39;, &quot;ProjectController.index&quot;).middleware(&#39;auth&#39;) Route.post(&#39;projects&#39;, &quot;ProjectController.create&quot;).middleware(&#39;auth&#39;) Route.delete(&#39;projects/:id&#39;, &quot;ProjectController.destroy&quot;).middleware(&#39;auth&#39;) Route.patch(&#39;projects/:id&#39;, &quot;ProjectController.update&quot;).middleware(&#39;auth&#39;) Route.post(&quot;projects/:id/tasks&quot;, &quot;TaskController.create&quot;).middleware(&#39;auth&#39;) Route.get(&quot;projects/:id/tasks&quot;, &quot;TaskController.index&quot;).middleware(&#39;auth&#39;) Route.delete(&quot;tasks/:id&quot;, &quot;TaskController.destroy&quot;).middleware(&quot;auth&quot;) Route.patch(&quot;tasks/:id&quot;, &quot;TaskController.update&quot;).middleware(&quot;auth&quot;) }).prefix(&quot;api&quot;) . Database . Setup . By default the database is configured to be sqlite. To change this, there is a line in the config/database.js file where you can change the sqlite to another provider. . connection: Env.get(&#39;DB_CONNECTION&#39;, &#39;sqlite&#39;), . Whichever provider you choose, you need to install the nodejs driver for it via npm/yarn. I believe you can omit the –save, as it’s a default flag. . npm install sqlite3 --save . Migrations . Now that the database is selected and the driver is installed, we need to setup our database schema using migration scripts. . You can find a default user table defined in database/migrations/somenumber_user.js . &#39;use strict&#39; /** @type {import(&#39;@adonisjs/lucid/src/Schema&#39;)} */ const Schema = use(&#39;Schema&#39;) class UserSchema extends Schema { up () { this.create(&#39;users&#39;, (table) =&gt; { table.increments() table.string(&#39;username&#39;, 80).notNullable().unique() table.string(&#39;email&#39;, 254).notNullable().unique() table.string(&#39;password&#39;, 60).notNullable() table.timestamps() }) } down () { this.drop(&#39;users&#39;) } } module.exports = UserSchema . Another example from the project schema created in the tutorial to show how to reference fields in another value. . &#39;use strict&#39; /** @type {import(&#39;@adonisjs/lucid/src/Schema&#39;)} */ const Schema = use(&#39;Schema&#39;) class ProjectSchema extends Schema { up () { this.create(&#39;projects&#39;, (table) =&gt; { table.increments() table.integer(&#39;user_id&#39;).unsigned().references(&#39;id&#39;).inTable(&#39;users&#39;) table.string(&#39;title&#39;, 255) table.timestamps() }) } down () { this.drop(&#39;projects&#39;) } } module.exports = ProjectSchema . Once you define a few of your database schemas in the migration scripts, you can generate the database tables by running. . adonis migration:run . If you ever need to drop the database and recreate from scratch you can run . adonis migration:refresh . Now that the database schema is generated in the database, we need a way to access the data. . Lucid Models . Adonis.js uses something called Lucid ORM(Object-Relational Mapping) which creates a class-like interface for database content. . The User model default configuration is shown below. The only real things to note is the hook definition for hashing the password before adding it to the database and how the tokens() method is defined. . &#39;use strict&#39; /** @type {typeof import(&#39;@adonisjs/lucid/src/Lucid/Model&#39;)} */ const Model = use(&#39;Model&#39;) /** @type {import(&#39;@adonisjs/framework/src/Hash&#39;)} */ const Hash = use(&#39;Hash&#39;) class User extends Model { static boot () { super.boot() /** * A hook to hash the user password before saving * it to the database. */ this.addHook(&#39;beforeSave&#39;, async (userInstance) =&gt; { if (userInstance.dirty.password) { userInstance.password = await Hash.make(userInstance.password) } }) } /** * A relationship on tokens is required for auth to * work. Since features like `refreshTokens` or * `rememberToken` will be saved inside the * tokens table. * * @method tokens * * @return {Object} */ tokens () { return this.hasMany(&#39;App/Models/Token&#39;) } } module.exports = User . The configuration built in the tutorial for the projects model is much simpler . &#39;use strict&#39; /** @type {typeof import(&#39;@adonisjs/lucid/src/Lucid/Model&#39;)} */ const Model = use(&#39;Model&#39;) class Project extends Model { user() { return this.belongsTo(&quot;App/Models/User&quot;) } tasks() { return this.hasMany(&quot;App/Models/Task&quot;) } } module.exports = Project . We can see the different ways we interact with the Lucid ORM models here in our ProjectController. . &#39;use strict&#39; const Project = use(&quot;App/Models/Project&quot;) const AuthService = use(&quot;App/Services/AuthorizationService&quot;) class ProjectController { async index({auth}) { const user = await auth.getUser(); return await user.projects().fetch(); } async create({request, auth}) { //Authenticating with our token const user = await auth.getUser(); //Object deconstruction to get the title of hte project const {title} = request.all(); //There are 3 ways we can do this in a way that associates the project with the user. /* 1. Use the constructor and give it the user_id manually. const project = await Project.create({ user_id: user.id, title }) * */ /* Use project.fill({}) or project.title=&quot;something&quot; on a new project object * const project = new Project(); project.title = &quot;Hello world&quot; * or project.fill({ title }) Then save it with await user.projects().save(project); */ const project = new Project(); project.fill({ title }); //Then saving it to associate it with the user await user.projects().save(project); return project; } //Adding params to the input object gives us the query parameters from the route. async destroy({response, auth, params}) { const user = await auth.getUser(); const { id } = params; // Will return us the project model if it exists const project = await Project.find(id); //Ensure the user that is auth&#39;d is the owner of the project. AuthService.verifyPermission(project, user); await project.delete(); // return response.status(403); return project; } async update({auth, params, request}) { const user = await auth.getUser(); const { id } = params; const project = await Project.find(id); AuthService.verifyPermission(project,user); project.merge(request.only(&#39;title&#39;)) await project.save(); return project; } } module.exports = ProjectController . Authentication . Authentication in Adonis is really simple. Similar to the database configuration, we choose an auth provider in config/auth.js. . Below you can see a trimmed down verison of the default configuration where we are using jwt tokens and the jwt object associates that with the lucid orm. Adonis also provides various other auth schemes and even social authentication so you don’t need things like firebase auth. . &#39;use strict&#39; /** @type {import(&#39;@adonisjs/framework/src/Env&#39;)} */ const Env = use(&#39;Env&#39;) module.exports = { authenticator: &#39;jwt&#39;, jwt: { serializer: &#39;lucid&#39;, model: &#39;App/Models/User&#39;, scheme: &#39;jwt&#39;, uid: &#39;email&#39;, password: &#39;password&#39;, options: { secret: Env.get(&#39;APP_KEY&#39;) } }, . To use the authentication we can refer back to the UserController.login method where we pass the auth object in with the request, and attempt authentication. . async login({request, auth}) { // request.all groups together all the request parameters, then we use object deconstruction to get the necessary items const {email, password} = request.all(); //Auth attempt const token = await auth.attempt(email, password); return token; } . Then every route that needed authentication we defined the route with the auth middleware . Route.get(&#39;projects&#39;, &quot;ProjectController.index&quot;).middleware(&#39;auth&#39;) . Below is an example from the ProjectController.index method where we pass in the auth object and get the user specific model from the database. . async index({auth}) { const user = await auth.getUser(); return await user.projects().fetch(); } . Testing the API with Postman . The last thing about the backend to note, is perhaps one of the most important. Testing your API is something you do from the first route configuration, so having a good tool to use is imperative. . Postman is a fantastic tool for doing API testing that even if I don’t use the web technologies in this tutorial ever again, I’ll certainly keep postman around for the future. . Here is a general overview of what postman looks like . The key features I wanted to show from postman were . Collections / folders | Creating a request | Environments | Test scripts | . Collections &amp; Folders . As you can see on the left, we have a collections tab where we can define groups of requests and subdivide them into their own folders. This is a fantastic way to organize your projects. To create a folder, simple right click on the collection and select “create folder”. . . Creating a request . To create a request in the subfolder or collection, you can either click on the + button in the middle of the screen shown in the first screenshot, or right click on the collection/folder and select “create a request”. . From there it’s simple to define what type of request it is, the body, headers, etc. . when you’re finished, you can save it to the specific collection/folder and even write a description on the request. . Environments . Environments are one of the coolest things in Postman that I surprisingly didn’t see in other REST client extensions I had on my browser. Basically what they do is allow you to define global variables for use in the selected environment. . You can create an environment by selecting the environment button on the top right, creating one and defining variables in the pop-up screen below. . Once you’ve defined your variables, you can access them anywhere in your requests using handlebar style expressions . In the below screenshot you can see we’ve substituted both the server address, the email, and password with our environmental variables. . . Test scripts . This is something not covered in the tutorial, but something I found fascinating is that you can define pre &amp; post request scripts to run. I imagine this is used often for response validation, but I found few other uses for it . Setting the token after users login to manage multiple users | Changing project &amp; task IDs after index / create requests | . This is all done in the Tests tab on the request. . . Frontend Development . I’m probably not going to go into as much depth as was necessary on the backend, I’m just going to touch on some of the key topics that I might forget in the future. . Topics I will cover . Setup | Components | Routing / views | Vuex store | Differences &amp; problems I encountered | . Setup . Installation . The vue documentation suggests installing their official CLI, but most enthusiasts seem to be switching to Vite. . I used their CLI for this project and installed it globally . npm install -g @vue/cli . Then to create the project we use the CLI binary and select Vue 3 preview as our preset . vue create client . At this point, we’re able to launch the dev server from within the client folder which will allow for hot reloading(changes are seen live). . npm run serve . Now with the project scaffolded out, we can install our various frontend dependencies . Installing dependencies . Our project uses the following depdencies . vuex - State management | vue-router - Frontend routing | vuex-persistedstate - Allows the vuex state to be saved to the client, great for login tokens. | vuex-router-sync - Syncs the router with vuex so you can access the current route from the store. Not sure why this is terribly useful yet. | axios - For HTTP requests from the client | primevue - The choosen frontend component library | primeflex - Flexbox css stuff for primevue | primeicons - Primeface’s official icon library, I tried this and it was a bit too limited in selection. | lodash - They included this dependency but I don’t remember ever using it. | . Later I included material icons stylesheet in the index.html header, but you can probably install that here too. . To install all of these depdencies you can just run this in your client folder. . npm install vuex-persistedstate vuex-router-sync axios primevue primeflex vue add vuex vue add vue-router . Setting up vuex . If we installed vuex from vue-cli, then it should have auto-generated a folder src/store with a file called index.js inside of it. It’s also already setup . The only thing we’ve really changed is we are using vuex in strict mode, which doesn’t allow code outside of our mutations to alter our Vuex state. This allows for easier debugging. . import { createStore } from &#39;vuex&#39; export default createStore({ strict: true, state: { }, mutations: { }, actions: { }, modules: { } }) . Setting up vuex-persistedstate . In order to setup vuex-persistedstate we need to modify our vuex store index file under src/store/index.js . Setup is simple by just importing it and adding it to our plugins property of our base store. . import createPersistedState from &#39;vuex-persistedstate&#39; import { createStore } from &#39;vuex&#39; export default createStore({ strict: true, state: { }, mutations: { }, actions: { }, modules: { }, plugins: [ createPersistedState() ] }) . Note, during development it might be better to disable persisted state. . Vuex-router-sync . Vuex-router-sync is quick to setup. We just need to add two lines to our src/main.js. Add these two lines before creating the app and doing .use(router), and we’re golden. . //Import vuex-router-sync import { sync } from &#39;vuex-router-sync&#39; //Syncs the store with the router sync(store, router); . Axios . In order to make web requests, we need to define our base Axios object. . So we created a file in the root server directory called http.js which uses the store to grab the baseURL &amp; the auth token. . import axios from &#39;axios&#39;; import store from &#39;./store/&#39;; export default () =&gt; { return axios.create({ baseURL: store.state.baseURL, timeout: 4000, headers: { Authorization: `Bearer ${store.state.authentication.token}` } }) } . Setting up primevue . First we need to tell Vue to use Primevue for components, and we can do that by editing src/main.js . Our final main.js looks like this. . import { createApp } from &#39;vue&#39; import App from &#39;./App.vue&#39; import router from &#39;./router&#39; import store from &#39;./store&#39; //Import vuex-router-sync import { sync } from &#39;vuex-router-sync&#39; //Import PrimeVue to use import PrimeVue from &quot;primevue/config&quot; //Syncs the store with the router sync(store, router); createApp(App).use(store).use(router).use(PrimeVue).mount(&#39;#app&#39;) . Then in order to actually use primevue css, we need to import it somewhere and since App.vue is our root component, it’s a fantastic place. So in the script section of App.vue . import &quot;primevue/resources/themes/vela-blue/theme.css&quot; import &quot;primevue/resources/primevue.min.css&quot; import &quot;primeflex/primeflex.css&quot; . Then I also set the background color of the body in the css section of the App.vue to match the theme . body { background-color: var(--surface-b); color: var(--text-color); } #app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; } . Proxying our requests to our adonis dev server . In order to code our requests as they would be on the live server, we need to create a proxy to our adonis dev server. . To do this we need to create a file in our root client directory called “vue.config.js” and define our target like this. . module.exports = { devServer: { proxy: { &#39;/api&#39;: { target: &#39;http://localhost:3333&#39; } } } } . Now all requests from our axios requests that start with /api will proxy to the adonis server as long as our environment is set to development. . Components . Components are the heart and soul of Vue.js. They can be thought of as the complete encapsulation of the logic, styling, and templating of any object in your webpage. I highly suggest reading up on them if you’re not familiar, because you will be lost if you don’t. . Projects scaffolded out using the Vue CLI will often use single file components with a structure like this. Where the template tags contain HTML, script contains the javascript logic and lifecycle hooks, and the style tags define css relative to this component. . &lt;template&gt; &lt;div class=&quot;something&quot;&gt; Hello world &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { } &lt;/script&gt; &lt;style&gt; .something { color: blue; } &lt;/style&gt; . A minimalistic example of a real component we used in our project is the CreateRecord component. . This component . Is composed of multiple sub-components | Emits events based on actions we defined. | Defines ‘props’ which is data we can pass to the component at time of creation. | Can be reused anywhere in our application and is used in both the Projects &amp; Tasks panels. | . &lt;template&gt; &lt;div class=&quot;p-grid&quot;&gt; &lt;InputText :placeholder=&quot;placeholder&quot; @update:model-value=&quot;$emit(&#39;input&#39;, $event)&quot; :value=&quot;value&quot; @keyup.enter=&quot;$emit(&#39;create&#39;)&quot; class=&quot;p-inputtext-lg p-col&quot; :disabled=&quot;disabled&quot; /&gt; &lt;Button class=&quot;p-col-fixed p-ml-2&quot; style=&quot;width: 90px;&quot; @click=&quot;$emit(&#39;create&#39;)&quot; :disabled=&quot;disabled&quot; &gt; &lt;i class=&quot;material-icons&quot; @click=&quot;iclicked&quot;&gt;add_circle&lt;/i&gt; Create &lt;/Button&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import Button from &quot;primevue/button&quot; import InputText from &quot;primevue/inputtext&quot; export default { components: { Button, InputText }, emits: [&#39;input&#39;, &#39;create&#39;], props: { placeholder: { type: String, required: false }, value: { type: String, required: false }, disabled: { type: Boolean, default: false } } } &lt;/script&gt; . I could keep going on, but this is more of a brief overview. . Routing &amp; Views . Earlier we installed a frontend router called “vue-router”. What frontend routers let us do is navigate our webpage without refreshing, which is extremely useful considering most single page applications are quite hefty. . In order to create a page we can navigate to on the frontend, we define a component for it under the views/ directory. These are no different than any other component other than they get mounted in our App.vue in place of . &lt;router-view /&gt; . An example view is our Projects.vue. Notice how concise this view is. We stuffed all of our logic in the sub-components project-panel and tasks-panel, so we have a much cleaner view component. . &lt;template&gt; &lt;div class=&quot;p-grid p-mt-4&quot;&gt; &lt;project-panel class=&quot;p-col-4&quot;&gt;&lt;/project-panel&gt; &lt;tasks-panel class=&quot;p-col-8&quot;&gt;&lt;/tasks-panel&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import ProjectPanel from &quot;../components/Projects.vue&quot; import TasksPanel from &quot;../components/Tasks.vue&quot; import { mapGetters } from &#39;vuex&#39; export default { components: { ProjectPanel, TasksPanel }, computed: { ...mapGetters(&#39;authentication&#39;, [ &#39;isLoggedIn&#39; ]) }, mounted() { if(!this.isLoggedIn) { this.$router.push(&#39;/login&#39;) } } } &lt;/script&gt; . Now that we have a Projects.vue defined, in order to navigate to it we need to define the route in our router/index.js. The final router for this project ended up looking like this. Notice it lazy loading everything other than the root component. . import { createRouter, createWebHashHistory } from &#39;vue-router&#39; import Projects from &#39;../views/Projects.vue&#39; const routes = [ { path: &#39;/&#39;, name: &#39;Projects&#39;, component: Projects }, { path: &#39;/about&#39;, name: &#39;About&#39;, // route level code-splitting // this generates a separate chunk (about.[hash].js) for this route // which is lazy-loaded when the route is visited. component: () =&gt; import(/* webpackChunkName: &quot;about&quot; */ &#39;../views/About.vue&#39;) }, { path: &#39;/register&#39;, name: &#39;Register&#39;, component: () =&gt; import (&#39;../views/Register.vue&#39;) }, { path: &#39;/login&#39;, name: &#39;Login&#39;, component: () =&gt; import (&#39;../views/Login.vue&#39;) } ] const router = createRouter({ history: createWebHashHistory(), routes }) export default router . With both our view created and our route setup, in order to navigate to one of these routes we can either use router-links . &lt;router-link to=&quot;/&quot;&gt;Some text&lt;/router-link&gt; . or we can push a route programatically . $router.push(&quot;/&quot;) . We mostly use the latter since we’re navigating based on events. An example of this is in our Nav component we defined methods for our buttons to use as on click actions. . import { mapGetters, mapActions } from &#39;vuex&#39; import Toolbar from &quot;primevue/toolbar&quot; import Button from &quot;primevue/button&quot; export default { components: { Toolbar, Button }, data() { return { } }, computed: { ...mapGetters(&#39;authentication&#39;, [ &#39;isLoggedIn&#39; ]), }, methods: { ...mapActions(&#39;authentication&#39;, [ &#39;logout&#39; ]), on_projects() { this.$router.push(&quot;/&quot;) }, on_register() { this.$router.push(&quot;/register&quot;) }, on_login() { this.$router.push(&quot;/login&quot;) }, open_video() { window.open(&quot;https://www.youtube.com/watch?v=dfEZlcPvez8&quot;) } } } . Vuex store . Overview . So, vuex, or state management in general creates a synchronized central data store for all of the components and logic of the application to access. . This allows us to . Centralize our logic | Synchronize multiple fields to one value | Live track other components | Cache hella data | . Creating a store &amp; store anatomy . By default, when we install vuex from the Vue CLI (not npm), it creates src/store/index.js as a default store file. We’ve already added persisted-state to it, but let’s talk about the anatomy of this real quick. . Each store may contain . state - The truth / value of the objects | mutations - Synchronous methods defined that are allowed to alter the state values | actions - Methods that may be asynchronous that perform actions, which are sometimes groups of mutations &amp; asynchronous calls to the web. Think of this as the primary logic methods. | getters - Get methods for retrieving the state or a value based on the state. | modules - nested stores | . An example that shows off most of thes concepts is our authentication.js module. A note, by passing namespaced: true, all of the method and objects are namespaced to store.authentication.state.stuff . import HTTP from &#39;@/http&#39;; import router from &#39;../router&#39;; export default { namespaced: true, state: { registerEmail: &#39;&#39;, registerPassword: &#39;&#39;, registerError: null, token: null, loginEmail: &#39;&#39;, loginPassword: &#39;&#39;, loginError: null }, mutations: { setRegisterEmail(state, email) { state.registerEmail = email; }, setRegisterPassword(state, password) { state.registerPassword = password; }, setToken(state, token) { state.token = token; }, setRegisterError(state, error) { state.registerError = error; }, setLoginEmail(state, email) { state.loginEmail = email; }, setLoginPassword(state, password) { state.loginPassword = password; }, setLoginError(state, error) { state.loginError = error; } }, getters: { isLoggedIn(state) { return !!state.token; } }, actions: { register({ commit, state }) { commit(&#39;setRegisterError&#39;, null); return HTTP().post(&#39;/api/auth/register&#39;, { email: state.registerEmail, password: state.registerPassword }).then(({data}) =&gt; { commit(&#39;setToken&#39;, data.token); router.push(&#39;/&#39;); }).catch(() =&gt; { commit(&#39;setRegisterError&#39;, &#39;An error has occured trying to create your account.&#39;); }) }, logout({commit}) { commit(&#39;setToken&#39;, null); router.push(&quot;/login&quot;) }, login({state, commit}) { commit(&#39;setLoginError&#39;, null) return HTTP().post(&#39;/api/auth/login&#39;, { email: state.loginEmail, password: state.loginPassword }).then(({data}) =&gt; { commit(&#39;setToken&#39;, data.token) router.push(&#39;/&#39;) }).catch(() =&gt; { commit(&#39;setLoginError&#39;, &quot;An error occured while logging in.&quot;) }) } } } . Then to register the modules, we do so in the root store, index.js . import createPersistedState from &#39;vuex-persistedstate&#39; import { createStore } from &#39;vuex&#39; import authentication from &quot;./authentication&quot; import projects from &quot;./projects&quot; import tasks from &quot;./tasks&quot; export default createStore({ strict: true, state: { baseUrl: &#39;/api&#39; }, mutations: { }, actions: { }, modules: { authentication, projects, tasks }, plugins: [ createPersistedState() ] }) . Accessing the store . Accessing the store is typically done in the script area of components. Vuex contains a bunch of helper methods you can import and use to map the vuex methods and values to our components. You can see this in our Projects.vue panel component. . import Panel from &quot;primevue/panel&quot;; import EditableRecord from &quot;./EditableRecord&quot; import CreateRecord from &#39;./CreateRecord&#39;; import { mapState, mapMutations, mapActions, mapGetters } from &#39;vuex&#39; export default { components: { Panel, EditableRecord, CreateRecord }, computed: { ...mapState(&#39;projects&#39;, [ &#39;newProjectName&#39;, &#39;projects&#39;, &#39;activeProjectID&#39; ]), ...mapGetters(&#39;authentication&#39;, [ &#39;isLoggedIn&#39; ]) }, methods: { ...mapMutations(&#39;projects&#39;, [ &#39;setNewProjectName&#39;, &#39;updateRecordTitle&#39; ]), ...mapActions(&#39;projects&#39;, [ &#39;createProject&#39;, &#39;getProjects&#39;, &#39;deleteProject&#39;, &#39;saveProjectName&#39;, &#39;selectProject&#39; ]) }, mounted() { if(this.isLoggedIn) { this.getProjects() } } } . Differences &amp; challenges I encountered . I encountered a few differences between the tutorial and my own code. Mostly because of Vue 3.0 is a bit different and I’m using a different component library. . Text Fields . In the tutorial, he got away with being able to use the @input event mapping with vuetify text fields . &lt;v-text-field autofocus v-if=&quot;isEditMode&quot; :value=&quot;title&quot; @keyup.enter=&quot;$emit(&#39;onSave&#39;)&quot; @input=&quot;$emit(&#39;onInput&#39;, $event)&quot; &gt;&lt;/v-text-field&gt; . However this didn’t work for whatever reason with the PrimeVue InputText component. I thought it would work regardless because I was under the impression that events were passed to the root element of a component if you don’t define them, but perhaps I am wrong or we were overwriting some important event. . So I checked the source from their github to see what might be happening . &lt;template&gt; &lt;input :class=&quot;[&#39;p-inputtext p-component&#39;, {&#39;p-filled&#39;: filled}]&quot; :value=&quot;modelValue&quot; @input=&quot;onInput&quot; /&gt; &lt;/template&gt; &lt;script&gt; export default { emits: [&#39;update:modelValue&#39;], props: { modelValue: null }, methods: { onInput(event) { this.$emit(&#39;update:modelValue&#39;, event.target.value); } }, computed: { filled() { return (this.modelValue != null &amp;&amp; this.modelValue.toString().length &gt; 0) } } } &lt;/script&gt; . It looks like they don’t propagate the @input event and instead they implemented it with the expectation we’d be using the two way data binding provided by v-model. I don’t think that’s a good fit for use with vuex because we’re not allowed to change the state outside of mutations…. . So instead we hooked into the event they do propagate. . &lt;InputText :placeholder=&quot;placeholder&quot; @update:model-value=&quot;$emit(&#39;input&#39;, $event)&quot; :value=&quot;value&quot; @keyup.enter=&quot;$emit(&#39;create&#39;)&quot; class=&quot;p-inputtext-lg p-col&quot; :disabled=&quot;disabled&quot; /&gt; . Panel . In the tutorial video they created their own panel component since Vuetify didn’t have one out of the box. However, PrimeVue does and I’m not a fan of extra work lol. So we just skipped this. . Infinite recursion bug? . In the tutorial they used a component called Projects inside of their view called Projects. When I followed diligently I encountered an infinite loop breaking the page. . Code that breaks the universe (Inside of src/views/Projects.vue) . &lt;template&gt; &lt;div class=&quot;p-grid p-mt-4&quot;&gt; &lt;Projects class=&quot;p-col-4&quot;&gt;&lt;/Projects&gt; &lt;tasks-panel class=&quot;p-col-8&quot;&gt;&lt;/tasks-panel&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import Projects from &quot;../components/Projects.vue&quot; import TasksPanel from &quot;../components/Tasks.vue&quot; import { mapGetters } from &#39;vuex&#39; export default { components: { Projects, TasksPanel }, computed: { ...mapGetters(&#39;authentication&#39;, [ &#39;isLoggedIn&#39; ]) }, mounted() { if(!this.isLoggedIn) { this.$router.push(&#39;/login&#39;) } } } &lt;/script&gt; . Our routes.js . import { createRouter, createWebHashHistory } from &#39;vue-router&#39; import Projects from &#39;../views/Projects.vue&#39; const routes = [ { path: &#39;/&#39;, name: &#39;Projects&#39;, component: Projects }, { path: &#39;/about&#39;, name: &#39;About&#39;, // route level code-splitting // this generates a separate chunk (about.[hash].js) for this route // which is lazy-loaded when the route is visited. component: () =&gt; import(/* webpackChunkName: &quot;about&quot; */ &#39;../views/About.vue&#39;) }, { path: &#39;/register&#39;, name: &#39;Register&#39;, component: () =&gt; import (&#39;../views/Register.vue&#39;) }, { path: &#39;/login&#39;, name: &#39;Login&#39;, component: () =&gt; import (&#39;../views/Login.vue&#39;) } ] const router = createRouter({ history: createWebHashHistory(), routes }) export default router . My assumption is that either the Projects object we create in the import statement in routes.js is taking priority over the Projects object we import in the component or there is some sort of internal Vue object defined under the same name. . In any case, I fixed it by just importing it in the component as ProjectPanel instead of Projects. . Vue.set() . Vue3 doesn’t support Ie11, so we don’t need to use Vue.set since modern browsers can detect changes via proxies and we don’t need to explicitly tell vue to overwrite the getters and setters. . This doesn’t impact things too much tutorial-wise, but we didn’t need to use Vue.set on the tasks to set completed and track it. . Gluing things together . Building the frontend . In order to compress and package the frontend, we need to run the build script in our client directory. This will compile our frontend and stick the packaged version into the client/dist folder. . npm run build . Serving via adonis . In order to serve this with adonis, we just need to copy all the files from the client/dist folder to our server/public folder. . After that we need to tell adonis we want to serve the static folder public by enabling the static file middleware. This is done by uncommenting this line in the server/start/kernel.js file. . const serverMiddleware = [ //&#39;Adonis/Middleware/Static&#39;, &#39;Adonis/Middleware/Cors&#39; ] . Now we just edit our .env file to change our host to 0.0.0.0 so we allow all connections, our port to match whatever port we want to serve on, and our NODE_ENV to production. . HOST=0.0.0.0 PORT=8080 NODE_ENV=production APP_NAME=AdonisJs APP_URL=http://${HOST}:${PORT} CACHE_VIEWS=false APP_KEY=dHImA9BVBgQ5MXeyw2RZqoQdzNFMyZcP DB_CONNECTION=sqlite DB_HOST=127.0.0.1 DB_PORT=3306 DB_USER=root DB_PASSWORD= DB_DATABASE=adonis HASH_DRIVER=bcrypt . Now we just can call node on server.js in the server folder and our project is live. . node server.js . Closing . Even though this was written as my notes and thoughts during the project, I hope someone finds it useful someday. . Thanks for reading. .",
            "url": "https://www.kyso.dev/vue/primevue/webdev/2021/03/15/FirstCrudTODO.html",
            "relUrl": "/vue/primevue/webdev/2021/03/15/FirstCrudTODO.html",
            "date": " • Mar 15, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "About this blog",
            "content": "What is this all about? . Hmm, I initially started this blog because I was studying machine learning and was somewhat fascinated by the ability to do literate programming using jupyter notebooks. A concept I had only ever really encountered in emacs’ org mode. After seeing how well jupyter notebooks worked, I wanted to share my journey in ML with friends, aggregate resources to one spot, and teach people stuff eventually…butttttt then I needed a job and that dream more or less died. . Instead of studying machine learning, I mostly have been studying things that I think could land me a job sometime this year. . So what now? . Well, instead of just posting about ML, why not post about anything? I learn cool shit every day and am just now starting my web development journey, so why not share that? I’m sure I’ll appreciate documenting my thought process someday and perhaps others will find it interesting or educational. . Gonna keep this one short and just post again soon. . Thank you all for reading. .",
            "url": "https://www.kyso.dev/meta/2021/03/14/About.html",
            "relUrl": "/meta/2021/03/14/About.html",
            "date": " • Mar 14, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://www.kyso.dev/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://www.kyso.dev/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Greetings all, I’m Rathma. . I’m just a guy who chases after a variety of ~addictions~ passions. Often times that has been programming over the last 10-11 years because I just have a genuine passion for learning new things and this field is constantly evolving. I discovered some time ago that I also really enjoy teaching, and someday I hope to become a professor that inspires a passion similar to mine in any field. Until then, I’m just going to share my journey learning a variety of topics here and hopefully somebody finds it interesting or useful. . Maybe someday if I’m feeling cute I’ll update this and the index into a real page. .",
          "url": "https://www.kyso.dev/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.kyso.dev/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}